{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133c7cd5-ea06-4a39-9e89-4cbed17cda76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import EvnOneStock\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936656e-5623-420b-87f0-17660c171880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 190  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 3.4e+03      |\n",
      "|    ep_rew_mean          | -1.35e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 178          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010557764 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -0.00382     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.73         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.4e+03     |\n",
      "|    ep_rew_mean          | -1.35e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 178         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002281548 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.9         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000697   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 23.5        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 定义自定义特征提取器 和 简单的 mlp_extractor 自定义\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_input_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, features_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.layers(observations)\n",
    "\n",
    "# 2. 配置 policy_kwargs\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    "    # 自定义 mlp_extractor 就在这里：\n",
    "    # net_arch=dict(\n",
    "    #     pi=[128, 64],  # 策略网络 (Actor) 的隐藏层：256 -> 128 -> 64\n",
    "    #     vf=[64, 64]    # 价值网络 (Critic) 的隐藏层：256 -> 64 -> 64\n",
    "    # )\n",
    ")\n",
    "\n",
    "# 3. 创建模型\n",
    "\n",
    "df = pd.read_csv(\"ohlcv_000001.SZ.csv\").fillna(0)\n",
    "\n",
    "env = EvnOneStock.SingleStockTradingEnv(df)\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(total_timesteps=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3ab04-5203-4350-a4c5-fdc28becdf3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
