{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1352cc5a-501d-47c2-a661-65b148acefd4",
   "metadata": {},
   "source": [
    "# 自定义 policy 模块中的 feature_extractor 和 mlp_extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8429fc6e-8178-4d8d-be05-1358a1ca36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import EvnOneStock\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b2655c-9f57-48ce-a986-a6cabb1ad4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 197  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 10   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2469c644ec0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 自定义特征提取器（保持你的代码）\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_input_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, features_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.layers(observations)\n",
    "\n",
    "# 2. 修改后的 policy_kwargs\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    "    # 重点：对于股票交易这类连续动作，使用 Squashed Gaussian 或简单的 Tanh 激活有时有帮助\n",
    "    # 但 SB3 的 PPO 默认在输出层之后不加激活函数，它靠 Box 空间的 Bound 来裁剪动作。\n",
    "    net_arch=dict(\n",
    "        pi=[128, 64], \n",
    "        vf=[128, 64]\n",
    "    ),\n",
    "    # 可以选择激活函数，Tanh 在连续控制任务中通常比 ReLU 更平滑\n",
    "    activation_fn=th.nn.Tanh \n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"ohlcv_000001.SZ.csv\").fillna(0)\n",
    "\n",
    "env = EvnOneStock.SingleStockTradingEnv(df)\n",
    "\n",
    "# 3. 创建模型\n",
    "# 注意：SB3 会根据 env.action_space 自动识别是连续动作还是离散动作\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebc7d4-1757-4dfe-8ef0-8f0c0381c9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56b64a83-035c-49a5-909c-b1657c0eb1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共有 1 行包含空值。\n",
      "         date     open     high      low    close  volume\n",
      "156  19911111  45.5264  45.5264  45.5264  45.5264     NaN\n"
     ]
    }
   ],
   "source": [
    "# 返回所有包含至少一个缺失值的行\n",
    "null_rows = df[df.isnull().any(axis=1)]\n",
    "\n",
    "print(f\"总共有 {len(null_rows)} 行包含空值。\")\n",
    "print(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3967887e-c7ae-483a-83e7-47d2a7202828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter loc (Tensor of shape (1, 1)) of distribution Normal(loc: tensor([[nan]], device='cuda:0'), scale: tensor([[1.]], device='cuda:0')) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan]], device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m env = EvnOneStock.SingleStockTradingEnv(df)\n\u001b[32m     33\u001b[39m model = PPO(\u001b[33m\"\u001b[39m\u001b[33mMlpPolicy\u001b[39m\u001b[33m\"\u001b[39m, env, policy_kwargs=policy_kwargs, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:311\u001b[39m, in \u001b[36mPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[32m    304\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> SelfPPO:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:324\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_timesteps < total_timesteps:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     continue_training = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:202\u001b[39m, in \u001b[36mOnPolicyAlgorithm.collect_rollouts\u001b[39m\u001b[34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[32m    201\u001b[39m     obs_tensor = obs_as_tensor(\u001b[38;5;28mself\u001b[39m._last_obs, \u001b[38;5;28mself\u001b[39m.device)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     actions, values, log_probs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m actions = actions.cpu().numpy()\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:654\u001b[39m, in \u001b[36mActorCriticPolicy.forward\u001b[39m\u001b[34m(self, obs, deterministic)\u001b[39m\n\u001b[32m    652\u001b[39m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[32m    653\u001b[39m values = \u001b[38;5;28mself\u001b[39m.value_net(latent_vf)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m distribution = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m actions = distribution.get_actions(deterministic=deterministic)\n\u001b[32m    656\u001b[39m log_prob = distribution.log_prob(actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:694\u001b[39m, in \u001b[36mActorCriticPolicy._get_action_dist_from_latent\u001b[39m\u001b[34m(self, latent_pi)\u001b[39m\n\u001b[32m    691\u001b[39m mean_actions = \u001b[38;5;28mself\u001b[39m.action_net(latent_pi)\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_dist, DiagGaussianDistribution):\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maction_dist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_dist, CategoricalDistribution):\n\u001b[32m    696\u001b[39m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[32m    697\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.action_dist.proba_distribution(action_logits=mean_actions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:164\u001b[39m, in \u001b[36mDiagGaussianDistribution.proba_distribution\u001b[39m\u001b[34m(self, mean_actions, log_std)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[32m    158\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    161\u001b[39m \u001b[33;03m:return:\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    163\u001b[39m action_std = th.ones_like(mean_actions) * log_std.exp()\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[38;5;28mself\u001b[39m.distribution = \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\torch\\distributions\\normal.py:60\u001b[39m, in \u001b[36mNormal.__init__\u001b[39m\u001b[34m(self, loc, scale, validate_args)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     59\u001b[39m     batch_shape = \u001b[38;5;28mself\u001b[39m.loc.size()\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\pyvenv\\rl\\Lib\\site-packages\\torch\\distributions\\distribution.py:72\u001b[39m, in \u001b[36mDistribution.__init__\u001b[39m\u001b[34m(self, batch_shape, event_shape, validate_args)\u001b[39m\n\u001b[32m     70\u001b[39m         valid = constraint.check(value)\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._is_all_true(valid):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     73\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     77\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m             )\n\u001b[32m     79\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: Expected parameter loc (Tensor of shape (1, 1)) of distribution Normal(loc: tensor([[nan]], device='cuda:0'), scale: tensor([[1.]], device='cuda:0')) to satisfy the constraint Real(), but found invalid values:\ntensor([[nan]], device='cuda:0')"
     ]
    }
   ],
   "source": [
    "# 1. 定义自定义特征提取器 和 简单的 mlp_extractor 自定义\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_input_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, features_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, observations: th.Tensor) -> th.Tensor:\n",
    "        return self.layers(observations)\n",
    "\n",
    "# 2. 配置 policy_kwargs\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCombinedExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=256),\n",
    "    # 自定义 mlp_extractor 就在这里：\n",
    "    # net_arch=dict(\n",
    "    #     pi=[128, 64],  # 策略网络 (Actor) 的隐藏层：256 -> 128 -> 64\n",
    "    #     vf=[64, 64]    # 价值网络 (Critic) 的隐藏层：256 -> 64 -> 64\n",
    "    # )\n",
    ")\n",
    "\n",
    "# 3. 创建模型\n",
    "\n",
    "df = pd.read_csv(\"ohlcv_000001.SZ.csv\").fillna(0)\n",
    "\n",
    "env = EvnOneStock.SingleStockTradingEnv(df)\n",
    "model = PPO(\"MlpPolicy\", env, policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(total_timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7aea6ea-d8d1-4c9a-a270-2d64b8e333a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 状态测试 ---\n",
      "输入状态: [-1.3300587  0.816699   0.0824696  1.2880276]\n",
      "动作概率: 向左(0): 14.47%, 向右(1): 85.53%\n",
      "最终决策: 1\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "# 1. 采样状态\n",
    "random_obs = env.observation_space.sample()\n",
    "\n",
    "# 2. 准备 Tensor 并确保设备一致\n",
    "# model.device 会自动返回 'cuda' 或 'cpu'\n",
    "obs_tensor = th.as_tensor(random_obs).float().unsqueeze(0).to(model.device)\n",
    "\n",
    "# 3. 手动推断分布\n",
    "with th.no_grad():\n",
    "    # 获取动作分布\n",
    "    dist = model.policy.get_distribution(obs_tensor)\n",
    "    \n",
    "    # 提取概率（转回 CPU 以便 numpy/print 处理）\n",
    "    probs = dist.distribution.probs.cpu().numpy()[0]\n",
    "    \n",
    "    print(f\"--- 状态测试 ---\")\n",
    "    print(f\"输入状态: {random_obs}\")\n",
    "    print(f\"动作概率: 向左(0): {probs[0]:.2%}, 向右(1): {probs[1]:.2%}\")\n",
    "    \n",
    "    # 选出概率最大的动作\n",
    "    action = np.argmax(probs)\n",
    "    print(f\"最终决策: {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0019ccb8-77e3-4f20-93ae-4a90a8a22b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3300587,  0.816699 ,  0.0824696,  1.2880276], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcd9ffc-b938-4456-81e1-4a34203a7844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b98e206-47ba-4be7-9a34-33cb48c053bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315767588112, 2315767588112, 2315767588112)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(model.policy.features_extractor), id(model.policy.vf_features_extractor), id(model.policy.pi_features_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c150e7-a915-46d0-9f26-0ac43cd7068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# 1. 定义自定义特征提取器 和 mlp_extractor 自定义\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "# 1. 定义一个完全自定义的 MlpExtractor 类\n",
    "class MyCustomMlpExtractor(nn.Module):\n",
    "    def __init__(self, feature_dim: int):\n",
    "        super().__init__()\n",
    "        # 定义输出维度，必须告知 Policy 最终输出给 action_net 的维度是多少\n",
    "        self.latent_dim_pi = 64\n",
    "        self.latent_dim_vf = 64\n",
    "\n",
    "        # 策略网络分支：加入 Dropout 层作为示例\n",
    "        self.policy_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(128, self.latent_dim_pi),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 价值网络分支\n",
    "        self.value_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.Tanh(), # 甚至可以在这里用不同的激活函数\n",
    "            nn.Linear(128, self.latent_dim_vf),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, features: th.Tensor):\n",
    "        # 返回 (policy_latent, value_latent)\n",
    "        return self.policy_net(features), self.value_net(features)\n",
    "\n",
    "    # 为了兼容性，SB3 需要这两个方法\n",
    "    def forward_actor(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.policy_net(features)\n",
    "\n",
    "    def forward_critic(self, features: th.Tensor) -> th.Tensor:\n",
    "        return self.value_net(features)\n",
    "\n",
    "# 2. 定义一个新的 Policy 类来使用这个 Extractor\n",
    "class CustomPolicy(ActorCriticPolicy):\n",
    "    def _build_mlp_extractor(self) -> None:\n",
    "        # 这里用我们自定义的类替换默认的 MlpExtractor\n",
    "        self.mlp_extractor = MyCustomMlpExtractor(self.features_dim)\n",
    "\n",
    "# 3. 使用这个自定义 Policy\n",
    "model = PPO(CustomPolicy, env, policy_kwargs=policy_kwargs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef4e38eb-239f-409b-941b-6baf54f0af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomPolicy(\n",
       "  (features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCombinedExtractor(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MyCustomMlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6bfa43-e8f4-48a7-ab67-32242c3781ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = np.array([0.5], dtype=np.float32)\n",
    "state, reward, terminated, truncated, info = env.step(action)\n",
    "assert not np.any(np.isnan(state)), \"Observation contains NaN!\"\n",
    "assert not np.any(np.isinf(state)), \"Observation contains Inf!\"\n",
    "assert np.isfinite(reward), \"Reward is not finite!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e088053-09dd-4ead-ad8a-465fa608799b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21508a19-9760-4853-a601-d316d9722e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20381738-802b-425e-a10e-1241c41a15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "import EvnOneStock\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02b70f9b-7d03-4508-9ae9-5dc8d2688442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ohlcv_000001.SZ.csv\")\n",
    "\n",
    "env = EvnOneStock.SingleStockTradingEnv(df=df, lookback_n=5)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "\n",
    "info_dict = {\n",
    "    # \"state\":[],\n",
    "    \"reward\":[],\n",
    "    \"terminated\":[],\n",
    "    \"truncated\":[],\n",
    "    \"portfolio_value\":[],\n",
    "    \"position\":[],\n",
    "    \"drawdown\":[],\n",
    "    \"current_step\":[],\n",
    "    \"prev_close\":[],\n",
    "    \"open_price\":[],\n",
    "    \"close_price\":[],\n",
    "    \"prev_position\":[],\n",
    "    \"delta_position\":[],\n",
    "}\n",
    "    \n",
    "for i in range(6):\n",
    "    action = np.array([0], dtype=np.float32)\n",
    "    if i%3==1:\n",
    "        action = np.array([0.5], dtype=np.float32)\n",
    "    elif i%3==2:\n",
    "        action = np.array([1], dtype=np.float32)\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    info_dict[\"reward\"].append(reward)\n",
    "    info_dict[\"terminated\"].append(terminated)\n",
    "    info_dict[\"truncated\"].append(truncated)\n",
    "    for k in list(info_dict.keys())[3:]:\n",
    "        info_dict[k].append(info[k])\n",
    "\n",
    "info_pd = pd.DataFrame(info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa228556-e700-433b-9ca0-d2d1e4d7dbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>terminated</th>\n",
       "      <th>truncated</th>\n",
       "      <th>portfolio_value</th>\n",
       "      <th>position</th>\n",
       "      <th>drawdown</th>\n",
       "      <th>current_step</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>prev_position</th>\n",
       "      <th>delta_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.010093</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>994953.742641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>7</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.08</td>\n",
       "      <td>47.08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.034708</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>980160.462695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>8</td>\n",
       "      <td>47.08</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.019840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>980160.462695</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>9</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.15</td>\n",
       "      <td>46.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.024774</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>977718.026006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>10</td>\n",
       "      <td>46.15</td>\n",
       "      <td>45.92</td>\n",
       "      <td>45.92</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reward  terminated  truncated  portfolio_value  position  drawdown  \\\n",
       "0  0.000000       False      False   1000000.000000       0.0  0.000000   \n",
       "1  0.000000       False      False   1000000.000000       0.5  0.000000   \n",
       "2 -0.010093       False      False    994953.742641       1.0  0.005046   \n",
       "3 -0.034708       False      False    980160.462695       0.0  0.019840   \n",
       "4 -0.019840       False      False    980160.462695       0.5  0.019840   \n",
       "5 -0.024774       False      False    977718.026006       1.0  0.022282   \n",
       "\n",
       "   current_step  prev_close  open_price  close_price  prev_position  \\\n",
       "0             5       47.80       47.56        47.56            0.0   \n",
       "1             6       47.56       47.56        47.56            0.0   \n",
       "2             7       47.56       47.08        47.08            0.5   \n",
       "3             8       47.08       46.38        46.38            1.0   \n",
       "4             9       46.38       46.15        46.15            0.0   \n",
       "5            10       46.15       45.92        45.92            0.5   \n",
       "\n",
       "   delta_position  \n",
       "0             0.0  \n",
       "1             0.5  \n",
       "2             0.5  \n",
       "3            -1.0  \n",
       "4             0.5  \n",
       "5             0.5  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd402c1a-5c91-4f04-bff4-3831c4b3a307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19910403</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19910404</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19910405</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19910408</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19910409</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19910410</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19910411</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>47.56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19910412</td>\n",
       "      <td>47.08</td>\n",
       "      <td>47.08</td>\n",
       "      <td>47.08</td>\n",
       "      <td>47.08</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19910416</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.38</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19910417</td>\n",
       "      <td>46.15</td>\n",
       "      <td>46.15</td>\n",
       "      <td>46.15</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   open   high    low  close  volume\n",
       "0  19910403  49.00  49.00  49.00  49.00     1.0\n",
       "1  19910404  48.76  48.76  48.76  48.76     3.0\n",
       "2  19910405  48.52  48.52  48.52  48.52     2.0\n",
       "3  19910408  48.04  48.04  48.04  48.04     2.0\n",
       "4  19910409  47.80  47.80  47.80  47.80     4.0\n",
       "5  19910410  47.56  47.56  47.56  47.56    15.0\n",
       "6  19910411  47.56  47.56  47.56  47.56     0.0\n",
       "7  19910412  47.08  47.08  47.08  47.08     8.0\n",
       "8  19910416  46.38  46.38  46.38  46.38     2.0\n",
       "9  19910417  46.15  46.15  46.15  46.15     1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22cc6c05-3cf0-4165-83bf-8118f8dbe032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47.56, 47.56, 47.56, 47.56,  0.  , 47.08, 47.08, 47.08, 47.08,\n",
       "        8.  , 46.38, 46.38, 46.38, 46.38,  2.  , 46.15, 46.15, 46.15,\n",
       "       46.15,  1.  , 45.92, 45.92, 45.92, 45.92,  4.  ,  1.  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fa76b3-a837-455f-a11a-c5a8fe87bb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EvnOneStock.SingleStockTradingEnv at 0x202c5102d50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvnOneStock.SingleStockTradingEnv(df=df, lookback_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf56f30-fdf5-484f-9e9a-c2b822577912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19910403</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19910404</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>48.76</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19910405</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>48.52</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19910408</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>48.04</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19910409</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>47.80</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   open   high    low  close  volume\n",
       "0  19910403  49.00  49.00  49.00  49.00     1.0\n",
       "1  19910404  48.76  48.76  48.76  48.76     3.0\n",
       "2  19910405  48.52  48.52  48.52  48.52     2.0\n",
       "3  19910408  48.04  48.04  48.04  48.04     2.0\n",
       "4  19910409  47.80  47.80  47.80  47.80     4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56964dd0-ad0a-415e-8b37-eef3c9f1686e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1a3ab8-aeff-45cf-876d-13f579d4e69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "      <th>terminated</th>\n",
       "      <th>truncated</th>\n",
       "      <th>portfolio_value</th>\n",
       "      <th>position</th>\n",
       "      <th>drawdown</th>\n",
       "      <th>current_step</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>open_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>prev_position</th>\n",
       "      <th>delta_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>61.2600</td>\n",
       "      <td>60.9500</td>\n",
       "      <td>60.9500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000634</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>21</td>\n",
       "      <td>60.9500</td>\n",
       "      <td>60.6400</td>\n",
       "      <td>60.6400</td>\n",
       "      <td>0.062328</td>\n",
       "      <td>-0.062328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000317</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>22</td>\n",
       "      <td>60.6400</td>\n",
       "      <td>60.0300</td>\n",
       "      <td>60.0300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000317</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.054134</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>23</td>\n",
       "      <td>60.0300</td>\n",
       "      <td>59.7300</td>\n",
       "      <td>59.7300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000843</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9.994202e+05</td>\n",
       "      <td>0.081649</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>24</td>\n",
       "      <td>59.7300</td>\n",
       "      <td>59.4400</td>\n",
       "      <td>59.4400</td>\n",
       "      <td>0.054134</td>\n",
       "      <td>0.027515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>-0.164601</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151222</td>\n",
       "      <td>2063</td>\n",
       "      <td>297.6043</td>\n",
       "      <td>293.4619</td>\n",
       "      <td>282.0704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>-0.151222</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151222</td>\n",
       "      <td>2064</td>\n",
       "      <td>282.0704</td>\n",
       "      <td>278.3164</td>\n",
       "      <td>286.4717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>-0.151222</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151222</td>\n",
       "      <td>2065</td>\n",
       "      <td>286.4717</td>\n",
       "      <td>286.8600</td>\n",
       "      <td>284.7888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>-0.149534</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.303691e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150447</td>\n",
       "      <td>2066</td>\n",
       "      <td>284.7888</td>\n",
       "      <td>283.4943</td>\n",
       "      <td>283.7532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>-0.150447</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.303691e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150447</td>\n",
       "      <td>2067</td>\n",
       "      <td>283.7532</td>\n",
       "      <td>283.7532</td>\n",
       "      <td>284.9183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reward  terminated  truncated  portfolio_value  position  drawdown  \\\n",
       "0     0.000000       False      False     1.000000e+06  0.062328  0.000000   \n",
       "1    -0.000634       False      False     9.996830e+05  0.000000  0.000317   \n",
       "2    -0.000317       False      False     9.996830e+05  0.000000  0.000317   \n",
       "3    -0.000317       False      False     9.996830e+05  0.054134  0.000317   \n",
       "4    -0.000843       False      False     9.994202e+05  0.081649  0.000580   \n",
       "...        ...         ...        ...              ...       ...       ...   \n",
       "2043 -0.164601       False      False     4.299765e+06  0.000000  0.151222   \n",
       "2044 -0.151222       False      False     4.299765e+06  0.000000  0.151222   \n",
       "2045 -0.151222       False      False     4.299765e+06  0.000000  0.151222   \n",
       "2046 -0.149534       False      False     4.303691e+06  1.000000  0.150447   \n",
       "2047 -0.150447       False      False     4.303691e+06  0.000000  0.150447   \n",
       "\n",
       "      current_step  prev_close  open_price  close_price  prev_position  \\\n",
       "0               20     61.2600     60.9500      60.9500       0.000000   \n",
       "1               21     60.9500     60.6400      60.6400       0.062328   \n",
       "2               22     60.6400     60.0300      60.0300       0.000000   \n",
       "3               23     60.0300     59.7300      59.7300       0.000000   \n",
       "4               24     59.7300     59.4400      59.4400       0.054134   \n",
       "...            ...         ...         ...          ...            ...   \n",
       "2043          2063    297.6043    293.4619     282.0704       1.000000   \n",
       "2044          2064    282.0704    278.3164     286.4717       0.000000   \n",
       "2045          2065    286.4717    286.8600     284.7888       0.000000   \n",
       "2046          2066    284.7888    283.4943     283.7532       0.000000   \n",
       "2047          2067    283.7532    283.7532     284.9183       1.000000   \n",
       "\n",
       "      delta_position  \n",
       "0           0.062328  \n",
       "1          -0.062328  \n",
       "2           0.000000  \n",
       "3           0.054134  \n",
       "4           0.027515  \n",
       "...              ...  \n",
       "2043       -1.000000  \n",
       "2044        0.000000  \n",
       "2045        0.000000  \n",
       "2046        1.000000  \n",
       "2047       -1.000000  \n",
       "\n",
       "[2048 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_pd = pd.read_csv(\"EvnOneStock_20260108152545.csv\")\n",
    "return_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d92b57-68ef-4fe0-8fa8-8578252fa24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portfolio_value</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.062328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.996830e+05</td>\n",
       "      <td>0.054134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.994202e+05</td>\n",
       "      <td>0.081649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>4.299765e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.303691e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>4.303691e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      portfolio_value  position\n",
       "0        1.000000e+06  0.062328\n",
       "1        9.996830e+05  0.000000\n",
       "2        9.996830e+05  0.000000\n",
       "3        9.996830e+05  0.054134\n",
       "4        9.994202e+05  0.081649\n",
       "...               ...       ...\n",
       "2043     4.299765e+06  0.000000\n",
       "2044     4.299765e+06  0.000000\n",
       "2045     4.299765e+06  0.000000\n",
       "2046     4.303691e+06  1.000000\n",
       "2047     4.303691e+06  0.000000\n",
       "\n",
       "[2048 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_pd[[\"portfolio_value\",\"position\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7aab5-a1eb-4a3c-8149-c2372c63ff62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
